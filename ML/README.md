
## UserKNN (User-based k-Nearest Neighbors) считается одной из лучших моделей для датасета **Movielens 100K** по следующим причинам:

### 1. **Эффективность UserKNN для небольших плотных датасетов**
- **Интуитивная персонализация**: UserKNN строит рекомендации, основываясь на похожих пользователях. В случае Movielens 100K это хорошо работает, так как плотность позволяет легко находить пользователей с похожими предпочтениями.
- **Отсутствие необходимости в сложной параметризации**: Для небольших плотных датасетов UserKNN может дать результаты, сопоставимые с более сложными методами, без необходимости в сложных настройках.

### 2. **Преимущества UserKNN**
- **Простота реализации**: UserKNN относительно легко реализовать, и его результаты могут быть хорошими без значительного увеличения вычислительных затрат.
- **Интерпретируемость**: Рекомендации можно объяснить, указав на конкретных "похожих" пользователей.
- **Стабильность**: Алгоритм не так чувствителен к небольшим изменениям в данных, как модели машинного обучения, которые могут переобучаться.

### 3. **Сравнение с другими подходами**
- **Матричная факторизация (SVD, ALS)**: Эти методы могут быть более эффективны на более крупных или разреженных датасетах, но для плотного и небольшого Movielens 100K UserKNN обеспечивает конкурентоспособные результаты с меньшей вычислительной сложностью.
- **ItemKNN**: В некоторых случаях ItemKNN (поиск похожих фильмов) может быть менее эффективным, так как разнообразие фильмов в Movielens 100K достаточно велико, и поиск похожих фильмов становится сложнее.
- **Нейросетевые модели**: Они обычно избыточны для небольших датасетов и требуют больше данных для обучения.


## Косинусное сходство 

- **Косинусное сходство** хорошо подходит для случаев, когда важно учитывать относительные предпочтения, а не абсолютные значения. Оно позволяет выявлять пользователей с похожими трендами, даже если их оценки в числовом выражении различаются.

## NDCG 
### 1. **NDCG** учитывает степень релевантности каждого элемента в выдаче. 
- Это позволяет не только определить, был ли результат полезным, но и насколько сильно он соответствует интересам пользователя.
### 2. **Дисконтирование по позиции:** 
- важность элемента уменьшается с увеличением его позиции в списке. Это имитирует реальное поведение пользователей, которые чаще обращают внимание на верхние результаты.
![image](https://github.com/user-attachments/assets/83ec018b-4ae5-4267-89e5-afa0aff0016c)
### 3. **Нормализация для сравнения списков:** 
- NDCG нормализуется относительно идеальной выдачи (Ideal DCG, IDCG), чтобы значение находилось в диапазоне от 0 до 1. Это позволяет сравнивать результаты различных алгоритмов независимо от длины списка или распределения релевантности:
![image](https://github.com/user-attachments/assets/f2b9e6ee-737f-4361-be62-8139f5e6a9e0)
### 4. Сравнение с другими метриками
- **Precision@k и Recall@k:**
Они не учитывают порядок результатов, что может приводить к одинаковым значениям для выдач с разным качеством ранжирования.
- **MAP (Mean Average Precision):**
Учитывает порядок, но рассчитана только для бинарной релевантности (релевантен/не релевантен).
- **MRR (Mean Reciprocal Rank):**
Смотрит только на первую релевантную позицию, игнорируя остальные элементы.
- **ROC-AUC:**
Не учитывает порядок релевантных элементов.

##  TF-IDF 
помогает определить, насколько важен термин в документе по сравнению с его распространенностью в других документах. Это позволяет выделить ключевые слова, которые лучше всего описывают содержание.
